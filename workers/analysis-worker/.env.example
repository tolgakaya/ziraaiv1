# ============================================
# ZiraAI Analysis Worker Configuration
# Multi-Provider AI Strategy Support
# ============================================

# Worker Identification
WORKER_ID=analysis-worker-001
NODE_ENV=development
LOG_LEVEL=info

# Concurrency & Performance
CONCURRENCY=60
HEALTH_CHECK_INTERVAL=30000
TIMEOUT=60000
RATE_LIMIT=350

# ============================================
# PROVIDER API KEYS
# ============================================
# At least one provider API key is required
# Multiple providers enable failover and load distribution

# OpenAI (gpt-4o-mini)
OPENAI_API_KEY=sk-...

# Google Gemini (gemini-2.0-flash-exp)
GEMINI_API_KEY=...

# Anthropic Claude (claude-3-5-sonnet)
ANTHROPIC_API_KEY=...

# ============================================
# PROVIDER SELECTION STRATEGY
# ============================================
# Available strategies:
#   FIXED           - Always use one specific provider
#   ROUND_ROBIN     - Distribute load evenly across all providers (DEFAULT)
#   COST_OPTIMIZED  - Prefer cheaper providers (Gemini > OpenAI > Anthropic)
#   QUALITY_FIRST   - Prefer higher quality (Anthropic > OpenAI > Gemini)
#   MESSAGE_BASED   - Use provider specified in message.provider field (legacy n8n)
#   WEIGHTED        - Custom weight distribution

PROVIDER_SELECTION_STRATEGY=ROUND_ROBIN

# ============================================
# STRATEGY-SPECIFIC CONFIGURATION
# ============================================

# --- FIXED Strategy ---
# Uncomment to always use one provider
# PROVIDER_SELECTION_STRATEGY=FIXED
# PROVIDER_FIXED=gemini

# --- WEIGHTED Strategy ---
# Uncomment for custom weight distribution
# PROVIDER_SELECTION_STRATEGY=WEIGHTED
# PROVIDER_WEIGHTS=[{"provider":"gemini","weight":50},{"provider":"openai","weight":30},{"provider":"anthropic","weight":20}]

# --- COST_OPTIMIZED Strategy ---
# Automatically uses cheapest provider first
# PROVIDER_SELECTION_STRATEGY=COST_OPTIMIZED

# --- QUALITY_FIRST Strategy ---
# Automatically uses highest quality provider
# PROVIDER_SELECTION_STRATEGY=QUALITY_FIRST

# --- MESSAGE_BASED Strategy ---
# Use provider from message field (legacy n8n behavior)
# PROVIDER_SELECTION_STRATEGY=MESSAGE_BASED

# ============================================
# PROVIDER METADATA (Dynamic Cost & Quality)
# ============================================
# Optional: Override default cost and quality scores
# Useful for:
#   - Updated pricing from provider APIs
#   - A/B testing results (quality adjustments)
#   - Custom quality scoring based on domain-specific metrics
#
# Format: JSON object with provider metadata
# PROVIDER_METADATA={"gemini":{"costPerMillion":1.0,"qualityScore":7},"openai":{"costPerMillion":5.0,"qualityScore":8},"anthropic":{"costPerMillion":48.0,"qualityScore":10}}
#
# Default values (if not specified):
#   Gemini:    costPerMillion=1.087,  qualityScore=7  (Good)
#   OpenAI:    costPerMillion=5.125,  qualityScore=8  (Very Good)
#   Anthropic: costPerMillion=48.0,   qualityScore=10 (Excellent)
#
# Example: Adjust Gemini quality score after A/B testing
# PROVIDER_METADATA={"gemini":{"qualityScore":8.5}}
#
# Example: Update all costs after provider price changes
# PROVIDER_METADATA={"gemini":{"costPerMillion":0.9},"openai":{"costPerMillion":4.5},"anthropic":{"costPerMillion":45.0}}

# ============================================
# PROVIDER CONFIGURATION (Legacy - for OpenAI provider config)
# ============================================
PROVIDER=openai
PROVIDER_MODEL=gpt-4o-mini

# ============================================
# RABBITMQ CONFIGURATION (Multi-Provider Queues)
# ============================================
RABBITMQ_URL=amqp://localhost:5672

# Provider-Specific Queues (hardcoded in config, no need to set)
# - openai-analysis-queue: OpenAI GPT-4o-mini requests
# - gemini-analysis-queue: Google Gemini Flash 2.0 requests
# - anthropic-analysis-queue: Claude 3.5 Sonnet requests
# - raw-analysis-queue: Legacy/unprocessed requests

# Result and Error Queues
RESULT_QUEUE=analysis-results-queue
DLQ_QUEUE=analysis-dlq

# Message Processing Configuration
PREFETCH_COUNT=10  # Messages to fetch at once (higher = more concurrency)

# ============================================
# REDIS CONFIGURATION (Rate Limiting)
# ============================================
REDIS_URL=redis://localhost:6379
REDIS_KEY_PREFIX=ziraai:ratelimit:
REDIS_TTL=120

# ============================================
# PROVIDER SELECTION STRATEGY EXAMPLES
# ============================================

# Example 1: Cost Optimization (Gemini-only for lowest cost)
# PROVIDER_SELECTION_STRATEGY=FIXED
# PROVIDER_FIXED=gemini
# OPENAI_API_KEY=  # (leave empty)
# GEMINI_API_KEY=AIza...
# ANTHROPIC_API_KEY=  # (leave empty)
# Result: All analyses use Gemini ($0.075/M input)

# Example 2: Quality Priority (Anthropic-only for best results)
# PROVIDER_SELECTION_STRATEGY=FIXED
# PROVIDER_FIXED=anthropic
# OPENAI_API_KEY=  # (leave empty)
# GEMINI_API_KEY=  # (leave empty)
# ANTHROPIC_API_KEY=sk-ant-...
# Result: All analyses use Claude ($3/M input)

# Example 3: Balanced Load Distribution (All providers, even split)
# PROVIDER_SELECTION_STRATEGY=ROUND_ROBIN
# OPENAI_API_KEY=sk-...
# GEMINI_API_KEY=AIza...
# ANTHROPIC_API_KEY=sk-ant-...
# Result: 33% OpenAI, 33% Gemini, 33% Anthropic

# Example 4: Cost-Optimized with Failover (Use cheap first, fallback to others)
# PROVIDER_SELECTION_STRATEGY=COST_OPTIMIZED
# OPENAI_API_KEY=sk-...
# GEMINI_API_KEY=AIza...
# ANTHROPIC_API_KEY=sk-ant-...
# Result: Gemini first, OpenAI second, Anthropic last

# Example 5: Custom Weighted Distribution (70% Gemini, 20% OpenAI, 10% Anthropic)
# PROVIDER_SELECTION_STRATEGY=WEIGHTED
# PROVIDER_WEIGHTS=[{"provider":"gemini","weight":70},{"provider":"openai","weight":20},{"provider":"anthropic","weight":10}]
# OPENAI_API_KEY=sk-...
# GEMINI_API_KEY=AIza...
# ANTHROPIC_API_KEY=sk-ant-...
# Result: Majority on Gemini for cost savings, some OpenAI/Anthropic for quality checks

# Example 6: n8n Legacy Compatibility (Use message.provider field)
# PROVIDER_SELECTION_STRATEGY=MESSAGE_BASED
# OPENAI_API_KEY=sk-...
# GEMINI_API_KEY=AIza...
# ANTHROPIC_API_KEY=sk-ant-...
# Result: Provider selected based on message.provider field (backward compatible)

# ============================================
# COST ESTIMATES (per 1M analyses, ~8.5K input + 1.5K output tokens)
# ============================================
# Gemini (flash-2.0):     $1,087 per 1M
# OpenAI (gpt-4o-mini):   $5,125 per 1M
# Anthropic (claude-3.5): $48,000 per 1M

# ============================================
# RAILWAY DEPLOYMENT NOTES
# ============================================
# For Railway deployment, set these environment variables in Railway dashboard
# You can override any setting per environment (Staging, Production)
# 
# Recommended Railway Setup:
# - Staging: FIXED strategy with Gemini (cost testing)
# - Production: ROUND_ROBIN with all providers (reliability + cost balance)
